# Car Recommendation System - Project Summary

## ğŸ“‹ Overview

ÄÃ£ táº¡o xong **foundation** cho há»‡ thá»‘ng Car Recommendation System Ä‘áº§y Ä‘á»§ vá»›i cÃ¡c thÃ nh pháº§n:

### âœ… HoÃ n thÃ nh

1. **Docker Infrastructure** 
   - PostgreSQL (Data Platform vá»›i 3 layers: Raw/Silver/Gold)
   - Elasticsearch (Search Engine)
   - Qdrant (Vector Database)
   - Redis (Cache & Rate Limiting)
   - FastAPI Backend
   - ETL Worker

2. **Database Schema**
   - RAW layer: Direct CSV ingestion
   - SILVER layer: Cleaned, typed, normalized data
   - GOLD layer: Business-ready vá»›i `listing_latest` table
   - User authentication tables (users, preferences, interactions)
   - Tracking tables (favorites, search_history)
   - Data quality & lineage tables

3. **Backend API Structure**
   - FastAPI application vá»›i OpenAPI docs
   - Authentication endpoints (placeholder)
   - Search endpoints (placeholder)
   - Recommendation endpoints (placeholder)
   - Feedback & interaction endpoints (placeholder)
   - JWT security setup
   - Database connection pooling

4. **ETL Pipeline**
   - CSV â†’ RAW layer loader (âœ… complete)
   - RAW â†’ SILVER transformer (â³ to implement)
   - SILVER â†’ GOLD transformer (â³ to implement)
   - Elasticsearch sync (â³ to implement)
   - Qdrant embeddings sync (â³ to implement)

## ğŸ“ Project Structure

```
car-recsys-system/
â”œâ”€â”€ docker-compose.yml              â† Infrastructure definition
â”œâ”€â”€ README.md                       â† Full documentation
â”œâ”€â”€ QUICKSTART.md                   â† Setup guide
â”‚
â”œâ”€â”€ database/
â”‚   â””â”€â”€ init/
â”‚       â””â”€â”€ 01_create_schemas.sql   â† Complete schema (RAW/SILVER/GOLD)
â”‚
â”œâ”€â”€ backend/                        â† FastAPI application
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py                 â† Application entry
â”‚       â”œâ”€â”€ core/
â”‚       â”‚   â”œâ”€â”€ config.py           â† Settings
â”‚       â”‚   â”œâ”€â”€ security.py         â† JWT & password hashing
â”‚       â”‚   â””â”€â”€ database.py         â† DB connection
â”‚       â””â”€â”€ api/v1/
â”‚           â”œâ”€â”€ auth.py             â† Authentication endpoints
â”‚           â”œâ”€â”€ search.py           â† Search endpoints
â”‚           â”œâ”€â”€ listings.py         â† Vehicle details
â”‚           â”œâ”€â”€ recommendations.py  â† Recommendation endpoints
â”‚           â””â”€â”€ feedback.py         â† User interactions
â”‚
â”œâ”€â”€ etl/                            â† Data pipeline
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ app/pipeline/
â”‚       â””â”€â”€ load_csv.py             â† CSV â†’ RAW loader
â”‚
â””â”€â”€ datasets/                       â† Your CSV files go here
    â”œâ”€â”€ used_vehicles.csv
    â”œâ”€â”€ new_vehicles.csv
    â”œâ”€â”€ sellers.csv
    â”œâ”€â”€ vehicle_features.csv
    â”œâ”€â”€ reviews_ratings.csv
    â”œâ”€â”€ vehicle_images.csv
    â””â”€â”€ seller_vehicle_relationships.csv
```

## ğŸš€ Quick Start

### 1. Copy datasets
```bash
cd "/home/duc-nguyen16/Car Recsys Consultant Chatbot/car-recsys-system"
cp ../datasets/*.csv ./datasets/
```

### 2. Start services
```bash
docker-compose up -d
```

### 3. Wait for services (2-3 minutes)
```bash
docker-compose ps
# All should show "healthy"
```

### 4. Load data
```bash
# Load CSV to RAW
docker-compose run --rm etl-worker python -m app.pipeline.load_csv
```

### 5. Access API
- **Docs**: http://localhost:8000/docs
- **Health**: http://localhost:8000/health

## ğŸ¯ Next Steps - Implementation Priority

### Phase 1: Data Pipeline (Week 1)
- [ ] Implement `raw_to_silver.py`
  - Data cleaning & type conversion
  - Deduplication
  - Data quality checks
- [ ] Implement `silver_to_gold.py`
  - Compute derived fields (price_range, mileage_range, body_type)
  - Create `gold.listing_latest` materialized view
  - Aggregate ratings
- [ ] Implement `sync_elasticsearch.py`
  - Create index mappings
  - Sync from gold â†’ ES
  - Test full-text search
- [ ] Implement `sync_qdrant.py`
  - Generate embeddings with sentence-transformers
  - Create vector collection
  - Sync vehicle descriptions

### Phase 2: Authentication & User Management (Week 1-2)
- [ ] Complete authentication endpoints
  - User registration with email/password
  - Login with JWT token
  - Password hashing with bcrypt
  - Token refresh mechanism
- [ ] Implement user profile management
- [ ] Setup user preferences table
- [ ] Implement user interaction tracking

### Phase 3: Search & Discovery (Week 2)
- [ ] Implement search endpoint
  - Query parsing
  - Elasticsearch integration
  - Faceted filters (brand, price, fuel_type, etc.)
  - Pagination & sorting
- [ ] Implement listing details endpoint
- [ ] Implement compare vehicles endpoint
- [ ] Add caching with Redis

### Phase 4: Recommendation Engine (Week 3-4)
- [ ] **Baseline Recommender**
  - Content-based filtering (specs similarity)
  - Rule-based (budget, body type matching)
  - Popular items fallback
  
- [ ] **Dense Retrieval**
  - Vehicle description embeddings
  - User preference embeddings
  - Cosine similarity search in Qdrant
  
- [ ] **Collaborative Filtering**
  - User-item interaction matrix
  - Item-item similarity from user behavior
  
- [ ] **Hybrid Approach**
  - Candidate generation (100-500 items)
  - Cross-encoder reranking (top 20)
  - Explanation generation
  - Diversity optimization

### Phase 5: Analytics & Monitoring (Week 4)
- [ ] Setup Prometheus metrics
- [ ] Create Grafana dashboards
- [ ] Implement A/B testing framework
- [ ] Log analysis pipelines
- [ ] Recommendation quality metrics (MRR, NDCG, CTR)

### Phase 6: Frontend (Week 5+)
- [ ] React/Next.js UI
- [ ] Vehicle search interface
- [ ] User authentication flow
- [ ] Recommendation cards
- [ ] User profile & favorites
- [ ] Responsive design

## ğŸ“Š Data Flow

```
CSV Files
    â†“
[load_csv.py] â†’ RAW Layer (PostgreSQL)
    â†“
[raw_to_silver.py] â†’ SILVER Layer (Clean & Typed)
    â†“
[silver_to_gold.py] â†’ GOLD Layer (Business Ready)
    â†“
    â”œâ”€â†’ [sync_elasticsearch.py] â†’ Elasticsearch (Search)
    â””â”€â†’ [sync_qdrant.py] â†’ Qdrant (Vectors)
                            â†“
                    Backend API Services
                            â†“
                    Frontend UI / Mobile App
```

## ğŸ”‘ Key Features

### Implemented
âœ… Docker infrastructure
âœ… Database schema (3 layers)
âœ… API structure & endpoints scaffolding
âœ… Configuration management
âœ… Security setup (JWT, password hashing)
âœ… CSV â†’ RAW ETL job

### To Implement
â³ Data transformation jobs (RAWâ†’SILVERâ†’GOLD)
â³ Search integration (Elasticsearch)
â³ Vector search (Qdrant + embeddings)
â³ Authentication endpoints (full implementation)
â³ Recommendation engine (baseline â†’ hybrid)
â³ User interaction tracking
â³ Caching layer (Redis)
â³ Monitoring & metrics

## ğŸ› ï¸ Tech Stack

- **Backend**: FastAPI, Python 3.11
- **Database**: PostgreSQL 15
- **Search**: Elasticsearch 8.11
- **Vector DB**: Qdrant
- **Cache**: Redis
- **ML**: Sentence-Transformers, scikit-learn
- **Deployment**: Docker Compose
- **API Docs**: OpenAPI/Swagger

## ğŸ“ˆ Performance Targets

- **Search latency**: < 100ms (p95)
- **Recommendation latency**: < 500ms (p95)
- **Cache hit rate**: > 80%
- **API availability**: > 99.9%
- **Data freshness**: < 1 hour

## ğŸ” Security Checklist

- [x] JWT authentication setup
- [x] Password hashing (bcrypt)
- [ ] Rate limiting per user
- [ ] HTTPS/SSL (production)
- [ ] API key management
- [ ] Input validation
- [ ] SQL injection prevention (SQLAlchemy ORM)
- [ ] CORS configuration

## ğŸ“ Support & Documentation

- **API Docs**: http://localhost:8000/docs (when running)
- **Quick Start**: See `QUICKSTART.md`
- **Full Docs**: See `README.md`
- **Architecture**: See images in project root

## ğŸ“ Learning Resources

- FastAPI: https://fastapi.tiangolo.com/
- Elasticsearch: https://www.elastic.co/guide/
- Qdrant: https://qdrant.tech/documentation/
- Sentence Transformers: https://www.sbert.net/

---

**Status**: âœ… Foundation Complete | â³ Implementation In Progress

**Next Action**: Run `docker-compose up -d` and start implementing ETL transformations!
