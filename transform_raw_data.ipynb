{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be1c5b49",
   "metadata": {},
   "source": [
    "# Car Data Transformation Pipeline\n",
    "## Transform raw JSON data to CSV datasets for RecSys & Chatbot\n",
    "\n",
    "This notebook processes raw car data from JSON files and creates structured CSV datasets for:\n",
    "- **Recommendation System**: Vehicle features, pricing, ratings\n",
    "- **Chatbot**: Vehicle specifications, seller info, reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb9a06c",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3129669b",
   "metadata": {},
   "source": [
    "## 1.5. Setup Google Cloud Storage Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35407ca3",
   "metadata": {},
   "source": [
    "### Google Colab Authentication (Run this cell on Colab only)\n",
    "\n",
    "If running on Google Colab, uncomment and run the authentication code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b883c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines if running on Google Colab\n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "# print(\"✓ Authenticated with Google Cloud\")\n",
    "\n",
    "# Alternative: Use gcloud commands (uncomment if needed)\n",
    "# !gcloud auth application-default login\n",
    "# !gcloud auth application-default set-quota-project car-recsys-consultant-chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03701ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required package if not already installed\n",
    "try:\n",
    "    from google.cloud import storage\n",
    "    print(\"✓ google-cloud-storage already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing google-cloud-storage...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call(['pip', 'install', 'google-cloud-storage', '-q'])\n",
    "    from google.cloud import storage\n",
    "    print(\"✓ google-cloud-storage installed successfully\")\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ID = \"car-recsys-consultant-chatbot\"  # Your GCP project ID\n",
    "BUCKET_NAME = \"car_recsys_consultant_chatbot\"\n",
    "BASE_PATH = \"Car Recsys Consultant Chatbot\"\n",
    "\n",
    "print(f\"\\nProject ID: {PROJECT_ID}\")\n",
    "print(f\"Bucket: {BUCKET_NAME}\")\n",
    "print(f\"Base Path: {BASE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a477f2",
   "metadata": {},
   "source": [
    "## 2. Load Raw Data from Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe613ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import partial\n",
    "\n",
    "def download_and_parse_blob(blob, bucket_name):\n",
    "    \"\"\"Download and parse a single blob (for parallel processing)\"\"\"\n",
    "    try:\n",
    "        json_content = blob.download_as_text(encoding='utf-8')\n",
    "        json_data = json.loads(json_content)\n",
    "        json_data['_source_file'] = blob.name\n",
    "        json_data['_gcs_path'] = f\"gs://{bucket_name}/{blob.name}\"\n",
    "        return json_data, None\n",
    "    except Exception as e:\n",
    "        return None, (blob.name, str(e))\n",
    "\n",
    "def load_json_files_from_gcs(project_id, bucket_name, base_path, max_workers=20):\n",
    "    \"\"\"\n",
    "    Load all JSON files from Google Cloud Storage bucket with parallel processing\n",
    "    \n",
    "    Args:\n",
    "        project_id: GCP project ID\n",
    "        bucket_name: GCS bucket name\n",
    "        base_path: Base path prefix in bucket\n",
    "        max_workers: Number of parallel download threads (default: 20)\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"LOADING DATA FROM GOOGLE CLOUD STORAGE (OPTIMIZED)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Initialize GCS client with project ID\n",
    "        client = storage.Client(project=project_id)\n",
    "        bucket = client.bucket(bucket_name)\n",
    "        \n",
    "        print(f\"✓ Connected to project: {project_id}\")\n",
    "        print(f\"✓ Connected to bucket: {bucket_name}\")\n",
    "        print(f\"✓ Base path: {base_path}/\")\n",
    "        print(f\"✓ Parallel workers: {max_workers}\")\n",
    "        print(\"\\nScanning for JSON files...\")\n",
    "        \n",
    "        # List all JSON blobs\n",
    "        all_blobs = list(bucket.list_blobs(prefix=f\"{base_path}/\"))\n",
    "        json_blobs = [blob for blob in all_blobs if blob.name.endswith('.json')]\n",
    "        \n",
    "        total_files = len(json_blobs)\n",
    "        print(f\"Found {total_files} JSON files\")\n",
    "        \n",
    "        if total_files == 0:\n",
    "            print(\"\\n⚠ No JSON files found in the specified path\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"\\nDownloading and parsing files (using {max_workers} parallel threads)...\")\n",
    "        \n",
    "        data = []\n",
    "        errors = []\n",
    "        \n",
    "        # Parallel download and parse\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            download_func = partial(download_and_parse_blob, bucket_name=bucket_name)\n",
    "            future_to_blob = {executor.submit(download_func, blob): blob for blob in json_blobs}\n",
    "            \n",
    "            # Process completed tasks with progress bar\n",
    "            completed = 0\n",
    "            for future in as_completed(future_to_blob):\n",
    "                completed += 1\n",
    "                json_data, error = future.result()\n",
    "                \n",
    "                if json_data:\n",
    "                    data.append(json_data)\n",
    "                else:\n",
    "                    errors.append(error)\n",
    "                \n",
    "                # Progress indicator every 50 files\n",
    "                if completed % 50 == 0 or completed == total_files:\n",
    "                    print(f\"  Progress: {completed}/{total_files} files ({completed*100//total_files}%)\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"✓ Successfully loaded: {len(data)} JSON files\")\n",
    "        if errors:\n",
    "            print(f\"✗ Errors: {len(errors)} files\")\n",
    "            print(\"\\nFirst 5 errors:\")\n",
    "            for filename, error in errors[:5]:\n",
    "                print(f\"  - {filename}: {error}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error connecting to GCS: {e}\")\n",
    "        print(\"\\nPlease ensure:\")\n",
    "        print(\"1. You are authenticated with GCS\")\n",
    "        print(\"   - On Colab: Run authentication cell first\")\n",
    "        print(\"   - Local: gcloud auth application-default login\")\n",
    "        print(\"2. You have permission to access the bucket\")\n",
    "        print(\"3. The project ID, bucket name and path are correct\")\n",
    "        print(f\"\\nCurrent config:\")\n",
    "        print(f\"  Project: {project_id}\")\n",
    "        print(f\"  Bucket: {bucket_name}\")\n",
    "        print(f\"  Path: {base_path}/\")\n",
    "        return []\n",
    "\n",
    "# Load data from GCS with parallel processing\n",
    "print(\"Starting data load...\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "raw_data = load_json_files_from_gcs(PROJECT_ID, BUCKET_NAME, BASE_PATH, max_workers=20)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\n⏱ Total loading time: {elapsed_time:.2f} seconds\")\n",
    "if raw_data:\n",
    "    print(f\"   Average: {elapsed_time/len(raw_data):.3f} seconds per file\")\n",
    "\n",
    "# Display sample structure\n",
    "if raw_data:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SAMPLE DATA STRUCTURE\")\n",
    "    print(\"=\"*80)\n",
    "    sample = raw_data[0]\n",
    "    print(f\"Keys: {list(sample.keys())}\")\n",
    "    print(f\"New/Used: {sample.get('post', {}).get('new_used', 'Unknown')}\")\n",
    "    print(f\"Source: {sample.get('_source_file', 'Unknown')}\")\n",
    "    print(f\"GCS Path: {sample.get('_gcs_path', 'Unknown')}\")\n",
    "    \n",
    "    # Show distribution by condition\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA DISTRIBUTION\")\n",
    "    print(\"=\"*80)\n",
    "    conditions = {}\n",
    "    for item in raw_data:\n",
    "        condition = item.get('post', {}).get('new_used', 'Unknown')\n",
    "        # Handle None values\n",
    "        if condition is None:\n",
    "            condition = 'Unknown'\n",
    "        conditions[condition] = conditions.get(condition, 0) + 1\n",
    "    \n",
    "    # Sort with proper handling\n",
    "    for condition in sorted(conditions.keys()):\n",
    "        count = conditions[condition]\n",
    "        print(f\"  {condition}: {count} vehicles\")\n",
    "else:\n",
    "    print(\"\\n⚠ No data loaded. Please check your GCS configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe6a6e",
   "metadata": {},
   "source": [
    "## 3. Dataset 1: Vehicles (Used Cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8447dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_used_vehicles(data):\n",
    "    \"\"\"Extract vehicle information for USED cars\"\"\"\n",
    "    vehicles = []\n",
    "    \n",
    "    for item in data:\n",
    "        post = item.get('post') or {}\n",
    "        car = item.get('car') or {}\n",
    "        \n",
    "        # Only process USED cars\n",
    "        new_used = post.get('new_used', '')\n",
    "        if not new_used or str(new_used).lower() != 'used':\n",
    "            continue\n",
    "        \n",
    "        basics = post.get('basics_des') or {}\n",
    "        user_history = post.get('user_history_des') or {}\n",
    "        ratings = car.get('ratings') or {}\n",
    "        metadata = item.get('_metadata') or {}\n",
    "        \n",
    "        vehicle = {\n",
    "            # Basic Info\n",
    "            'vehicle_id': basics.get('VIN', ''),\n",
    "            'stock_number': basics.get('Stock #', ''),\n",
    "            'condition': post.get('new_used', ''),\n",
    "            'title': post.get('title', ''),\n",
    "            'brand': car.get('brand', ''),\n",
    "            'car_model': car.get('car_model', ''),\n",
    "            'car_name': car.get('car_name', ''),\n",
    "            \n",
    "            # Pricing & Mileage\n",
    "            'price': post.get('price', None),\n",
    "            'monthly_payment': post.get('monthly_payment', None),\n",
    "            'mileage': post.get('mileage', None),\n",
    "            'mileage_str': basics.get('Mileage', ''),\n",
    "            \n",
    "            # Specifications\n",
    "            'exterior_color': basics.get('Exterior color', ''),\n",
    "            'interior_color': basics.get('Interior color', ''),\n",
    "            'drivetrain': basics.get('Drivetrain', ''),\n",
    "            'mpg': basics.get('MPG', ''),\n",
    "            'fuel_type': basics.get('Fuel type', ''),\n",
    "            'transmission': basics.get('Transmission', ''),\n",
    "            'engine': basics.get('Engine', ''),\n",
    "            'vin': basics.get('VIN', ''),\n",
    "            \n",
    "            # Vehicle History\n",
    "            'accidents_damage': user_history.get('Accidents or damage', ''),\n",
    "            'one_owner': user_history.get('1-owner vehicle', ''),\n",
    "            'personal_use_only': user_history.get('Personal use only', ''),\n",
    "            \n",
    "            # Warranty\n",
    "            'warranty': post.get('warranty_des', ''),\n",
    "            \n",
    "            # Ratings (from car reviews)\n",
    "            'car_rating': car.get('car_rating', None),\n",
    "            'percentage_recommend': car.get('percentage_recommend', None),\n",
    "            'comfort_rating': ratings.get('Comfort', None),\n",
    "            'interior_rating': ratings.get('Interior', None),\n",
    "            'performance_rating': ratings.get('Performance', None),\n",
    "            'value_rating': ratings.get('Value', None),\n",
    "            'exterior_rating': ratings.get('Exterior', None),\n",
    "            'reliability_rating': ratings.get('Reliability', None),\n",
    "            \n",
    "            # Links\n",
    "            'vehicle_url': metadata.get('url', ''),\n",
    "            'car_review_link': car.get('review_link', ''),\n",
    "            'car_link': car.get('car_link', ''),\n",
    "            \n",
    "            # Metadata\n",
    "            'source_file': item.get('_source_file', ''),\n",
    "            'total_images': len(post.get('image') or []),\n",
    "            'has_ratings': metadata.get('has_ratings', False),\n",
    "            'data_complete': metadata.get('is_complete', False),\n",
    "        }\n",
    "        \n",
    "        vehicles.append(vehicle)\n",
    "    \n",
    "    df = pd.DataFrame(vehicles)\n",
    "    print(f\"Extracted {len(df)} USED vehicles\")\n",
    "    return df\n",
    "\n",
    "# Extract used vehicles\n",
    "df_used_vehicles = extract_used_vehicles(raw_data)\n",
    "print(\"\\nUsed Vehicles Dataset Shape:\", df_used_vehicles.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df_used_vehicles.columns.tolist())\n",
    "print(\"\\nSample Data:\")\n",
    "df_used_vehicles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e7cf1",
   "metadata": {},
   "source": [
    "## 4. Dataset 2: Vehicles (New Cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6d3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_new_vehicles(data):\n",
    "    \"\"\"Extract vehicle information for NEW cars\"\"\"\n",
    "    vehicles = []\n",
    "    \n",
    "    for item in data:\n",
    "        post = item.get('post') or {}\n",
    "        car = item.get('car') or {}\n",
    "        \n",
    "        # Only process NEW cars\n",
    "        new_used = post.get('new_used', '')\n",
    "        if not new_used or str(new_used).lower() != 'new':\n",
    "            continue\n",
    "        \n",
    "        basics = post.get('basics_des') or {}\n",
    "        user_history = post.get('user_history_des') or {}\n",
    "        ratings = car.get('ratings') or {}\n",
    "        metadata = item.get('_metadata') or {}\n",
    "        \n",
    "        vehicle = {\n",
    "            # Basic Info\n",
    "            'vehicle_id': basics.get('VIN', ''),\n",
    "            'stock_number': basics.get('Stock #', ''),\n",
    "            'condition': post.get('new_used', ''),\n",
    "            'title': post.get('title', ''),\n",
    "            'brand': car.get('brand', ''),\n",
    "            'car_model': car.get('car_model', ''),\n",
    "            'car_name': car.get('car_name', ''),\n",
    "            \n",
    "            # Pricing & Mileage\n",
    "            'price': post.get('price', None),\n",
    "            'monthly_payment': post.get('monthly_payment', None),\n",
    "            'mileage': post.get('mileage', None),\n",
    "            'mileage_str': basics.get('Mileage', ''),\n",
    "            \n",
    "            # Specifications\n",
    "            'exterior_color': basics.get('Exterior color', ''),\n",
    "            'interior_color': basics.get('Interior color', ''),\n",
    "            'drivetrain': basics.get('Drivetrain', ''),\n",
    "            'mpg': basics.get('MPG', ''),\n",
    "            'fuel_type': basics.get('Fuel type', ''),\n",
    "            'transmission': basics.get('Transmission', ''),\n",
    "            'engine': basics.get('Engine', ''),\n",
    "            'vin': basics.get('VIN', ''),\n",
    "            \n",
    "            # Vehicle History (usually null for new cars)\n",
    "            'accidents_damage': user_history.get('Accidents or damage', ''),\n",
    "            'one_owner': user_history.get('1-owner vehicle', ''),\n",
    "            'personal_use_only': user_history.get('Personal use only', ''),\n",
    "            \n",
    "            # Warranty\n",
    "            'warranty': post.get('warranty_des', ''),\n",
    "            \n",
    "            # Ratings (usually null for new cars without reviews)\n",
    "            'car_rating': car.get('car_rating', None),\n",
    "            'percentage_recommend': car.get('percentage_recommend', None),\n",
    "            'comfort_rating': ratings.get('Comfort', None),\n",
    "            'interior_rating': ratings.get('Interior', None),\n",
    "            'performance_rating': ratings.get('Performance', None),\n",
    "            'value_rating': ratings.get('Value', None),\n",
    "            'exterior_rating': ratings.get('Exterior', None),\n",
    "            'reliability_rating': ratings.get('Reliability', None),\n",
    "            \n",
    "            # Links\n",
    "            'vehicle_url': metadata.get('url', ''),\n",
    "            'car_review_link': car.get('review_link', ''),\n",
    "            'car_link': car.get('car_link', ''),\n",
    "            \n",
    "            # Metadata\n",
    "            'source_file': item.get('_source_file', ''),\n",
    "            'total_images': len(post.get('image') or []),\n",
    "            'has_ratings': metadata.get('has_ratings', False),\n",
    "            'data_complete': metadata.get('is_complete', False),\n",
    "        }\n",
    "        \n",
    "        vehicles.append(vehicle)\n",
    "    \n",
    "    df = pd.DataFrame(vehicles)\n",
    "    print(f\"Extracted {len(df)} NEW vehicles\")\n",
    "    return df\n",
    "\n",
    "# Extract new vehicles\n",
    "df_new_vehicles = extract_new_vehicles(raw_data)\n",
    "print(\"\\nNew Vehicles Dataset Shape:\", df_new_vehicles.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df_new_vehicles.columns.tolist())\n",
    "print(\"\\nSample Data:\")\n",
    "df_new_vehicles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04daaa20",
   "metadata": {},
   "source": [
    "## 5. Dataset 3: Sellers Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f2ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sellers(data):\n",
    "    \"\"\"Extract seller/dealer information\"\"\"\n",
    "    sellers = []\n",
    "    seen_sellers = set()\n",
    "    \n",
    "    for item in data:\n",
    "        seller = item.get('seller') or {}\n",
    "        \n",
    "        if not seller:\n",
    "            continue\n",
    "        \n",
    "        seller_key = seller.get('seller_key', '')\n",
    "        \n",
    "        # Avoid duplicates\n",
    "        if seller_key in seen_sellers:\n",
    "            continue\n",
    "        seen_sellers.add(seller_key)\n",
    "        \n",
    "        phone_info = seller.get('phone_info') or {}\n",
    "        hours = seller.get('hours') or {}\n",
    "        \n",
    "        seller_data = {\n",
    "            # Basic Info\n",
    "            'seller_key': seller_key,\n",
    "            'seller_name': seller.get('seller_name', ''),\n",
    "            'seller_link': seller.get('seller_link', ''),\n",
    "            \n",
    "            # Contact Info\n",
    "            'phone_new': phone_info.get('New', ''),\n",
    "            'phone_used': phone_info.get('Used', ''),\n",
    "            'phone_service': phone_info.get('Service', ''),\n",
    "            'destination': seller.get('destination', ''),\n",
    "            \n",
    "            # Business Hours\n",
    "            'sales_hours': hours.get('Sales hours', ''),\n",
    "            'service_hours': hours.get('Service hours', ''),\n",
    "            'hours_monday': hours.get('Monday', ''),\n",
    "            'hours_tuesday': hours.get('Tuesday', ''),\n",
    "            'hours_wednesday': hours.get('Wednesday', ''),\n",
    "            'hours_thursday': hours.get('Thursday', ''),\n",
    "            'hours_friday': hours.get('Friday', ''),\n",
    "            'hours_saturday': hours.get('Saturday', ''),\n",
    "            'hours_sunday': hours.get('Sunday', ''),\n",
    "            \n",
    "            # Ratings\n",
    "            'seller_rating': seller.get('seller_rating', None),\n",
    "            'seller_rating_count': seller.get('seller_rating_count', None),\n",
    "            \n",
    "            # Description\n",
    "            'description': seller.get('description', ''),\n",
    "            \n",
    "            # Images\n",
    "            'total_images': len(seller.get('images') or []),\n",
    "            'images_json': json.dumps(seller.get('images') or []),\n",
    "            \n",
    "            # Metadata\n",
    "            'source_file': item.get('_source_file', ''),\n",
    "        }\n",
    "        \n",
    "        sellers.append(seller_data)\n",
    "    \n",
    "    df = pd.DataFrame(sellers)\n",
    "    print(f\"Extracted {len(df)} unique sellers\")\n",
    "    return df\n",
    "\n",
    "# Extract sellers\n",
    "df_sellers = extract_sellers(raw_data)\n",
    "print(\"\\nSellers Dataset Shape:\", df_sellers.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df_sellers.columns.tolist())\n",
    "print(\"\\nSample Data:\")\n",
    "df_sellers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9116f7",
   "metadata": {},
   "source": [
    "## 6. Dataset 4: Vehicle Features (Used & New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a141bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vehicle_features(data):\n",
    "    \"\"\"Extract vehicle features (flattened from feature_des)\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for item in data:\n",
    "        post = item.get('post') or {}\n",
    "        basics = post.get('basics_des') or {}\n",
    "        feature_des = post.get('feature_des') or {}\n",
    "        \n",
    "        vehicle_id = basics.get('VIN', '')\n",
    "        condition = post.get('new_used', '')\n",
    "        \n",
    "        if not feature_des:\n",
    "            continue\n",
    "        \n",
    "        # Flatten features by category\n",
    "        for category, feature_list in feature_des.items():\n",
    "            if not isinstance(feature_list, list):\n",
    "                continue\n",
    "                \n",
    "            for feature_name in feature_list:\n",
    "                features.append({\n",
    "                    'vehicle_id': vehicle_id,\n",
    "                    'condition': condition,\n",
    "                    'title': post.get('title', ''),\n",
    "                    'feature_category': category,\n",
    "                    'feature_name': feature_name,\n",
    "                    'source_file': item.get('_source_file', ''),\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(features)\n",
    "    print(f\"Extracted {len(df)} vehicle features\")\n",
    "    return df\n",
    "\n",
    "# Extract vehicle features\n",
    "df_vehicle_features = extract_vehicle_features(raw_data)\n",
    "print(\"\\nVehicle Features Dataset Shape:\", df_vehicle_features.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df_vehicle_features.columns.tolist())\n",
    "\n",
    "# Show feature categories distribution\n",
    "print(\"\\nFeature Categories:\")\n",
    "print(df_vehicle_features['feature_category'].value_counts())\n",
    "\n",
    "print(\"\\nSample Data:\")\n",
    "df_vehicle_features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4bf2a",
   "metadata": {},
   "source": [
    "## 7. Dataset 5: Reviews & Ratings (Used Cars Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc807308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews(data):\n",
    "    \"\"\"Extract reviews and ratings from car model reviews (mainly for used cars)\"\"\"\n",
    "    reviews = []\n",
    "    \n",
    "    for item in data:\n",
    "        post = item.get('post') or {}\n",
    "        car = item.get('car') or {}\n",
    "        basics = post.get('basics_des') or {}\n",
    "        \n",
    "        # Only process items with car reviews\n",
    "        if not car or not car.get('reviews'):\n",
    "            continue\n",
    "        \n",
    "        vehicle_id = basics.get('VIN', '')\n",
    "        condition = post.get('new_used', '')\n",
    "        car_model = car.get('car_model', '')\n",
    "        car_name = car.get('car_name', '')\n",
    "        \n",
    "        for review in car.get('reviews', []):\n",
    "            ratings_breakdown = review.get('ratings_breakdown') or {}\n",
    "            \n",
    "            review_data = {\n",
    "                # Vehicle Info\n",
    "                'vehicle_id': vehicle_id,\n",
    "                'condition': condition,\n",
    "                'car_model': car_model,\n",
    "                'car_name': car_name,\n",
    "                'title': post.get('title', ''),\n",
    "                \n",
    "                # Review Info\n",
    "                'overall_rating': review.get('overall_rating', None),\n",
    "                'review_time': review.get('time', ''),\n",
    "                'user_name': review.get('user_name', ''),\n",
    "                'user_location': review.get('from', ''),\n",
    "                'review_text': review.get('review', ''),\n",
    "                \n",
    "                # Detailed Ratings\n",
    "                'comfort_rating': ratings_breakdown.get('Comfort', None),\n",
    "                'interior_rating': ratings_breakdown.get('Interior', None),\n",
    "                'performance_rating': ratings_breakdown.get('Performance', None),\n",
    "                'value_rating': ratings_breakdown.get('Value', None),\n",
    "                'exterior_rating': ratings_breakdown.get('Exterior', None),\n",
    "                'reliability_rating': ratings_breakdown.get('Reliability', None),\n",
    "                \n",
    "                # Metadata\n",
    "                'source_file': item.get('_source_file', ''),\n",
    "            }\n",
    "            \n",
    "            reviews.append(review_data)\n",
    "    \n",
    "    df = pd.DataFrame(reviews)\n",
    "    print(f\"Extracted {len(df)} reviews\")\n",
    "    return df\n",
    "\n",
    "# Extract reviews\n",
    "df_reviews = extract_reviews(raw_data)\n",
    "print(\"\\nReviews Dataset Shape:\", df_reviews.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df_reviews.columns.tolist())\n",
    "print(\"\\nRating Distribution:\")\n",
    "print(df_reviews['overall_rating'].value_counts().sort_index(ascending=False))\n",
    "print(\"\\nSample Data:\")\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd6d114",
   "metadata": {},
   "source": [
    "## 8. Dataset 6: Vehicle Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df07f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vehicle_images(data):\n",
    "    \"\"\"Extract vehicle images with metadata\"\"\"\n",
    "    images = []\n",
    "    \n",
    "    for item in data:\n",
    "        post = item.get('post') or {}\n",
    "        basics = post.get('basics_des') or {}\n",
    "        \n",
    "        vehicle_id = basics.get('VIN', '')\n",
    "        condition = post.get('new_used', '')\n",
    "        image_list = post.get('image') or []\n",
    "        \n",
    "        if not image_list:\n",
    "            continue\n",
    "        \n",
    "        for idx, image_url in enumerate(image_list):\n",
    "            images.append({\n",
    "                'vehicle_id': vehicle_id,\n",
    "                'condition': condition,\n",
    "                'title': post.get('title', ''),\n",
    "                'image_order': idx + 1,\n",
    "                'image_url': image_url,\n",
    "                'total_images': len(image_list),\n",
    "                'source_file': item.get('_source_file', ''),\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(images)\n",
    "    print(f\"Extracted {len(df)} vehicle images\")\n",
    "    return df\n",
    "\n",
    "# Extract vehicle images\n",
    "df_vehicle_images = extract_vehicle_images(raw_data)\n",
    "print(\"\\nVehicle Images Dataset Shape:\", df_vehicle_images.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df_vehicle_images.columns.tolist())\n",
    "print(\"\\nImages per vehicle statistics:\")\n",
    "print(df_vehicle_images.groupby('vehicle_id')['image_order'].count().describe())\n",
    "print(\"\\nSample Data:\")\n",
    "df_vehicle_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e925c682",
   "metadata": {},
   "source": [
    "## 9. Dataset 7: Seller-Vehicle Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2cd1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seller_vehicle_relationship(data):\n",
    "    \"\"\"Extract relationship between sellers and vehicles\"\"\"\n",
    "    relationships = []\n",
    "    \n",
    "    for item in data:\n",
    "        post = item.get('post') or {}\n",
    "        seller = item.get('seller') or {}\n",
    "        basics = post.get('basics_des') or {}\n",
    "        metadata = item.get('_metadata') or {}\n",
    "        \n",
    "        vehicle_id = basics.get('VIN', '')\n",
    "        seller_key = seller.get('seller_key', '')\n",
    "        \n",
    "        if not vehicle_id or not seller_key:\n",
    "            continue\n",
    "        \n",
    "        relationships.append({\n",
    "            'vehicle_id': vehicle_id,\n",
    "            'seller_key': seller_key,\n",
    "            'condition': post.get('new_used', ''),\n",
    "            'title': post.get('title', ''),\n",
    "            'seller_name': seller.get('seller_name', ''),\n",
    "            'price': post.get('price', None),\n",
    "            'stock_number': basics.get('Stock #', ''),\n",
    "            'vehicle_url': metadata.get('url', ''),\n",
    "            'source_file': item.get('_source_file', ''),\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(relationships)\n",
    "    print(f\"Extracted {len(df)} seller-vehicle relationships\")\n",
    "    return df\n",
    "\n",
    "# Extract seller-vehicle relationships\n",
    "df_seller_vehicles = extract_seller_vehicle_relationship(raw_data)\n",
    "print(\"\\nSeller-Vehicle Relationship Dataset Shape:\", df_seller_vehicles.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df_seller_vehicles.columns.tolist())\n",
    "print(\"\\nSample Data:\")\n",
    "df_seller_vehicles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e39c8",
   "metadata": {},
   "source": [
    "## 10. Data Quality Check & Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATA QUALITY SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "datasets = {\n",
    "    'Used Vehicles': df_used_vehicles,\n",
    "    'New Vehicles': df_new_vehicles,\n",
    "    'Sellers': df_sellers,\n",
    "    'Vehicle Features': df_vehicle_features,\n",
    "    'Reviews & Ratings': df_reviews,\n",
    "    'Vehicle Images': df_vehicle_images,\n",
    "    'Seller-Vehicle Relationships': df_seller_vehicles,\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  - Total Records: {len(df)}\")\n",
    "    print(f\"  - Columns: {len(df.columns)}\")\n",
    "    print(f\"  - Memory Usage: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df) * 100).round(2)\n",
    "    cols_with_missing = missing[missing > 0]\n",
    "    \n",
    "    if len(cols_with_missing) > 0:\n",
    "        print(f\"  - Columns with missing values: {len(cols_with_missing)}\")\n",
    "        print(f\"    Top 3 missing:\")\n",
    "        for col in cols_with_missing.head(3).index:\n",
    "            print(f\"      • {col}: {missing[col]} ({missing_pct[col]}%)\")\n",
    "    else:\n",
    "        print(f\"  - No missing values!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONDITION DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nUsed Vehicles: {len(df_used_vehicles)}\")\n",
    "print(f\"New Vehicles: {len(df_new_vehicles)}\")\n",
    "print(f\"Total: {len(df_used_vehicles) + len(df_new_vehicles)}\")\n",
    "\n",
    "# Price statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRICE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(df_used_vehicles) > 0:\n",
    "    print(\"\\nUsed Vehicles:\")\n",
    "    print(df_used_vehicles['price'].describe())\n",
    "\n",
    "if len(df_new_vehicles) > 0:\n",
    "    print(\"\\nNew Vehicles:\")\n",
    "    print(df_new_vehicles['price'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6197f11",
   "metadata": {},
   "source": [
    "## 11. Save All Datasets to CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ed904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"datasets\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING DATASETS TO CSV FILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save all datasets\n",
    "datasets_to_save = {\n",
    "    'used_vehicles.csv': df_used_vehicles,\n",
    "    'new_vehicles.csv': df_new_vehicles,\n",
    "    'sellers.csv': df_sellers,\n",
    "    'vehicle_features.csv': df_vehicle_features,\n",
    "    'reviews_ratings.csv': df_reviews,\n",
    "    'vehicle_images.csv': df_vehicle_images,\n",
    "    'seller_vehicle_relationships.csv': df_seller_vehicles,\n",
    "}\n",
    "\n",
    "for filename, df in datasets_to_save.items():\n",
    "    filepath = output_dir / filename\n",
    "    df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "    file_size = filepath.stat().st_size / 1024  # KB\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "    print(f\"  - Records: {len(df)}\")\n",
    "    print(f\"  - File size: {file_size:.2f} KB\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ALL DATASETS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nOutput directory: {output_dir.absolute()}\")\n",
    "print(f\"Total files: {len(datasets_to_save)}\")\n",
    "\n",
    "# List all created files\n",
    "print(\"\\nCreated files:\")\n",
    "for file in sorted(output_dir.glob(\"*.csv\")):\n",
    "    print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da5fd51",
   "metadata": {},
   "source": [
    "## 12. Dataset Documentation & Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf4e6c",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "\n",
    "#### 1. **used_vehicles.csv** (USED CARS)\n",
    "**Purpose**: Main dataset for used car recommendation system\n",
    "- **Key Fields**: vehicle_id, price, mileage, brand, model, ratings, specifications\n",
    "- **Use Cases**:\n",
    "  - Content-based filtering (by specs, features, price range)\n",
    "  - Collaborative filtering (based on ratings)\n",
    "  - Price prediction models\n",
    "  - Vehicle history analysis\n",
    "\n",
    "#### 2. **new_vehicles.csv** (NEW CARS)\n",
    "**Purpose**: Main dataset for new car recommendation system\n",
    "- **Key Fields**: vehicle_id, price, brand, model, specifications\n",
    "- **Use Cases**:\n",
    "  - New car recommendations\n",
    "  - Price comparison\n",
    "  - Feature-based filtering\n",
    "  - Brand analysis\n",
    "\n",
    "#### 3. **sellers.csv**\n",
    "**Purpose**: Dealer/seller information for chatbot context\n",
    "- **Key Fields**: seller_key, seller_name, ratings, contact_info, location\n",
    "- **Use Cases**:\n",
    "  - Dealer recommendations\n",
    "  - Contact information retrieval\n",
    "  - Seller rating analysis\n",
    "  - Location-based search\n",
    "\n",
    "#### 4. **vehicle_features.csv**\n",
    "**Purpose**: Detailed feature breakdown for filtering and recommendation\n",
    "- **Key Fields**: vehicle_id, feature_category, feature_name\n",
    "- **Use Cases**:\n",
    "  - Feature-based filtering (\"cars with backup camera\")\n",
    "  - Feature importance analysis\n",
    "  - Cross-vehicle feature comparison\n",
    "  - RecSys feature engineering\n",
    "\n",
    "#### 5. **reviews_ratings.csv** (USED CARS ONLY)\n",
    "**Purpose**: User reviews and sentiment for recommendation quality\n",
    "- **Key Fields**: vehicle_id, overall_rating, review_text, detailed_ratings\n",
    "- **Use Cases**:\n",
    "  - Sentiment analysis for chatbot responses\n",
    "  - Rating-based recommendations\n",
    "  - Review summarization\n",
    "  - User feedback analysis\n",
    "\n",
    "#### 6. **vehicle_images.csv**\n",
    "**Purpose**: Vehicle image URLs for visual presentation\n",
    "- **Key Fields**: vehicle_id, image_url, image_order\n",
    "- **Use Cases**:\n",
    "  - Visual display in chatbot/web interface\n",
    "  - Image-based search (future enhancement)\n",
    "  - Gallery generation\n",
    "\n",
    "#### 7. **seller_vehicle_relationships.csv**\n",
    "**Purpose**: Link vehicles to sellers for inventory queries\n",
    "- **Key Fields**: vehicle_id, seller_key, price, stock_number\n",
    "- **Use Cases**:\n",
    "  - Inventory management\n",
    "  - Seller-specific recommendations\n",
    "  - Price comparison across sellers\n",
    "  - Stock availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e98053",
   "metadata": {},
   "source": [
    "## 13. Quick Data Exploration Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba220f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Top 10 most reviewed car models (Used)\n",
    "if len(df_reviews) > 0:\n",
    "    print(\"=\"*80)\n",
    "    print(\"TOP 10 MOST REVIEWED CAR MODELS\")\n",
    "    print(\"=\"*80)\n",
    "    top_reviewed = df_reviews.groupby('car_name').agg({\n",
    "        'overall_rating': ['count', 'mean']\n",
    "    }).round(2)\n",
    "    top_reviewed.columns = ['review_count', 'avg_rating']\n",
    "    top_reviewed = top_reviewed.sort_values('review_count', ascending=False).head(10)\n",
    "    print(top_reviewed)\n",
    "\n",
    "# Example 2: Price range by brand (Used)\n",
    "if len(df_used_vehicles) > 0 and 'brand' in df_used_vehicles.columns:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PRICE STATISTICS BY BRAND (USED VEHICLES)\")\n",
    "    print(\"=\"*80)\n",
    "    brand_prices = df_used_vehicles[df_used_vehicles['brand'] != ''].groupby('brand')['price'].agg([\n",
    "        'count', 'min', 'mean', 'max'\n",
    "    ]).round(2)\n",
    "    brand_prices = brand_prices.sort_values('mean', ascending=False).head(10)\n",
    "    print(brand_prices)\n",
    "\n",
    "# Example 3: Most common vehicle features\n",
    "if len(df_vehicle_features) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TOP 15 MOST COMMON VEHICLE FEATURES\")\n",
    "    print(\"=\"*80)\n",
    "    feature_counts = df_vehicle_features.groupby(['feature_category', 'feature_name']).size().reset_index(name='count')\n",
    "    feature_counts = feature_counts.sort_values('count', ascending=False).head(15)\n",
    "    print(feature_counts.to_string(index=False))\n",
    "\n",
    "# Example 4: Seller ratings\n",
    "if len(df_sellers) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TOP RATED SELLERS (with 100+ reviews)\")\n",
    "    print(\"=\"*80)\n",
    "    top_sellers = df_sellers[df_sellers['seller_rating_count'] >= 100].sort_values(\n",
    "        'seller_rating', ascending=False\n",
    "    )[['seller_name', 'seller_rating', 'seller_rating_count', 'destination']].head(10)\n",
    "    print(top_sellers.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d025caba",
   "metadata": {},
   "source": [
    "## 14. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93af4bb",
   "metadata": {},
   "source": [
    "### ✅ Transformation Complete!\n",
    "\n",
    "#### What We Created:\n",
    "1. **7 Clean CSV Datasets** ready for RecSys & Chatbot\n",
    "2. **Separated Used vs New** vehicles for targeted analysis\n",
    "3. **Normalized data structure** across all tables\n",
    "4. **Rich feature extraction** from nested JSON\n",
    "\n",
    "#### Key Separations:\n",
    "- **Used Cars**: Include reviews, ratings, vehicle history\n",
    "- **New Cars**: Fresh inventory with minimal history data\n",
    "- **Sellers**: Centralized dealer information\n",
    "- **Features**: Granular feature data for filtering\n",
    "- **Reviews**: Sentiment and rating data for quality scoring\n",
    "\n",
    "#### Next Steps for RecSys:\n",
    "1. **Content-Based Filtering**: Use vehicle_features.csv + specifications\n",
    "2. **Collaborative Filtering**: Use reviews_ratings.csv for user preferences\n",
    "3. **Hybrid Approach**: Combine both with price, brand, ratings\n",
    "4. **Feature Engineering**: Create derived features (price_per_mile, feature_count, etc.)\n",
    "\n",
    "#### Next Steps for Chatbot:\n",
    "1. **Load all CSVs** into your knowledge base\n",
    "2. **Index reviews** for sentiment-based responses\n",
    "3. **Link sellers** to vehicles for dealer queries\n",
    "4. **Use features** for natural language filtering\n",
    "5. **Integrate images** for visual responses\n",
    "\n",
    "#### Data Quality Notes:\n",
    "- Check for missing VINs (vehicle_id)\n",
    "- Some new cars may lack reviews/ratings\n",
    "- Validate price ranges for outliers\n",
    "- Consider deduplication if needed"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
